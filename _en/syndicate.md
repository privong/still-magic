---
permalink: "/en/syndicate/"
title: "Syndicating Data"
questions:
- "FIXME"
objectives:
- "Write Python programs to download data sets using simple REST APIs."
- "Parse CSV data using the `csv` library."
- "Test a program that parses CSV using multiline strings."
keypoints:
- "FIXME"
---

A growing number of organizations make data sets available on the web in a style called [REST](../gloss/#g:rest),
which stands for REpresentational State Transfer.
When REST is used,
every data set is identified by a URL
and can be accessed through a set of functions
called an [application programming interface](../gloss/#g:api) (API).
This lesson will look at how to use these interfaces,
and how to provide data through them ourselves.

## How can I fetch data data from a website? {#s:syndicate-fetch}

The World Bank's [Climate Data API][climate-api]
provides data generated by 15 global circulation models.
According to the API's [home page][climate-api],
the data sets containing yearly averages for various values are identified by URLs of the form:

<code>http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/<em>VAR</em>/year/<em>ISO3</em>.<em>EXT</em></code>

where:

-   *VAR* is either `pr` (for precipitation) or `tas` (for "temperature at surface");
-   *ISO3* is the International Standards Organization (ISO)
    [3-letter code for a country][wikipedia-iso-country],
    such as "CAN" for Canada or "BRA" for Brazil;
    and
-   *EXT* (short for "extension") specifies the format we want the data in.
    There are several choices for format,
    but the simplest is [comma-separated values](../gloss/#g:csv) (CSV),
    in which each record is a row,
    and the values in each row are separated by commas.
    (CSV is frequently used for spreadsheet data.)

For example, if we want the average annual temperature in Canada as a CSV file, the URL is:

```text
http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/CAN.csv
```

If we paste that URL into a browser, it displays:

```text
year,data
1901,-7.67241907119751
1902,-7.862711429595947
1903,-7.910782814025879
...
2007,-6.819293975830078
2008,-7.2008957862854
2009,-6.997011661529541
```

> #### Behind the Scenes
>
> This particular data set might be stored in a file on the World Bank's server,
> or that server might:
>
> 1.  Receive our URL.
> 2.  Break it into pieces.
> 3.  Extract the three key fields (the variable, the country code, and the desired format).
> 4.  Fetch the desired data from a database.
> 5.  Format the data as CSV.
> 6.  Send that to our browser.
>
> As long as the World Bank doesn't change its URLs,
> we don't need to know which method it's using
> and it can switch back and forth between them without breaking our programs.

If we only wanted to look at data for a couple of countries,
we could just download those files one by one.
But we want to compare data for many different pairs of countries,
so we should write a program.

Python has a library called [Requests][requests] for running HTTP requests.
To install it, run:

```shell
$ pip install requests
```

(Note that `pip` is a program in its own right,
so the command above must be run in the shell,
and *not* from within Python itself.)
Once it is installed,
we can get the data we want like this:

```python
import requests

url = 'http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/CAN.csv'
response = requests.get(url)
if response.status_code != 200:
    print('Failed to get data:', response.status_code)
else:
    print('First 100 characters of data are')
    print(response.text[:100])
```
{: title="syndicate/get-tas-can.py"}
```text
First 100 characters of data are
year,data
1901,-7.67241907119751
1902,-7.862711429595947
1903,-7.910782814025879
1904,-8.15572929382
```

`requests.get` actually gets our data. More specifically, it:

-   creates a connection to the `climatedataapi.worldbank.org` server;
-   sends the URL `/climateweb/rest/v1/country/cru/tas/year/CAN.csv` to that server;
-   creates an object in memory on our computer to hold the response;
-   assigns a number to that object's `status_code` member variable to tell us whether the request succeeded or not; and
-   assigns the data sent back by the web server to the object's `text` member variable.

(We could just pass this URL as an argument to the `requests.get` call,
but assigning it to a variable makes it easier to find.)

The server can return many different [status codes](../gloss/#g:http-status-code);
the most common are:

| Code | Name                  | Meaning                                                                    |
|------|-----------------------|----------------------------------------------------------------------------|
| 200  | OK                    | The request has succeeded.                                                 |
| 204  | No Content            | The server has completed the request, but doesn't need to return any data. |
| 400  | Bad Request           | The request is badly formatted.                                            |
| 401  | Unauthorized          | The request requires authentication.                                       |
| 404  | Not Found             | The requested resource could not be found.                                 |
| 408  | Timeout               | The server gave up waiting for the client.                                 |
| 418  | I'm a teapot          | No, really...                                                              |
| 500  | Internal Server Error | An error occurred in the server.                                           |

200 (OK) is the one we want;
if we get anything else, the response probably doesn't contain actual data
(though it might contain an error message).

## How can I handle tabular data? {#s:syndicate-csv}

Our little program gets the data we want,
but returns it as one long character string rather than as a list of numbers.
There are two ways we could convert the former to the latter:

-   Write a function to split that string on newline characters to create lines,
    then split the lines on commas and convert the second part of each to a number.
-   Use a Python library to do this for us.

Most experienced programmers would say that the second approach is easier,
but "easy" is relative:
using standard libraries is only easier if we know that those libraries exist and how to use them.

Let's try the first approach.
To begin,
we create a file called `test-01.csv` that contains the following three lines:

```text
1901,12.3
1902,45.6
1903,78.9
```

It's easy to read this file line by line and (for example) report the length of each line:

```python
with open('test-01.csv', 'r') as reader:
    for line in reader:
        print(len(line))
```
{: title="syndicate/read-csv-01.py"}
```text
10
10
10
```

We can also split each line on commas to turn each one into a list of string fragments:

```python
with open('test-01.csv', 'r') as reader:
    for line in reader:
        fields = line.split(',')
        print(fields)
```
{: title="syndicate/read-csv-02.py"}
```text
['1901', '12.3\n']
['1902', '45.6\n']
['1903', '78.9\n']
```

The dates are correct,
but the values all end with `\n`.
This is an [escape sequence](../gloss/#g:escape-sequence) that represents
the newline character at the end of each line.
To get rid of it,
we should strip leading and trailing whitespace from each line before splitting it on commas:

```python
with open('test-01.csv', 'r') as reader:
    for line in reader:
        fields = line.strip().split(',')
        print(fields)
```
{: title="syndicate/read-csv-03.py"}
```text
['1901', '12.3']
['1902', '45.6']
['1903', '78.9']
```

Now let's have a look at how we could parse the data using standard Python libraries instead.
The library we'll use is called `csv`.
It doesn't read data itself:
instead, it takes the lines read by something else and turns them into lists of values by splitting on commas.
Here's one way to use it:

```python
import csv

with open('test-01.csv', 'r') as raw:
    cooked = csv.reader(raw)
    for record in cooked:
        print(record)
```
{: title="syndicate/read-csv-04.py"}
```text
['1901', '12.3']
['1902', '45.6']
['1903', '78.9']
```

Here,
`raw` reads data in the normal way,
while `cooked` is a [wrapper](../gloss/#g:wrapper)
that takes a line of text and turns it into a list of fields.

We can equally well give a `csv.reader` a list of strings rather than a file:

```python
import csv

with open('test-01.csv', 'r') as raw:
    lines = raw.readlines()
cooked = csv.reader(lines)
for record in cooked:
    print(record)
```
{: title="syndicate/read-csv-05.py"}
```text
['1901', '12.3']
['1902', '45.6']
['1903', '78.9']
```

Using the `csv` library doesn't seem any simpler than just splitting strings,
but look at what happens when we have data like this:

```text
"Meltzer, Marlyn Wescoff",1922,2008
"Spence, Frances Bilas",1922,2012
"Teitelbaum,Ruth Lichterman",1924,1986
```
{: title="syndicate/test-02.csv"}

With simple string splitting, our output is:

```text
['"Meltzer', ' Marlyn Wescoff"', '1922', '2008']
['"Spence', ' Frances Bilas"', '1922', '2012']
['"Teitelbaum', 'Ruth Lichterman"', '1924', '1986']
```

The double quotes are still there,
and the field containing each person's name has been split into pieces.
If we use the `csv` library,
on the other hand,
the output is:

```text
['Meltzer, Marlyn Wescoff', '1922', '2008']
['Spence, Frances Bilas', '1922', '2012']
['Teitelbaum,Ruth Lichterman', '1924', '1986']
```

because the library understands how to handle text fields containing commas
(and a lot more).

We need to do one more thing before using `csv` with the climate data.
When we use the World Bank's API to get data for a particular country,
it comes back as one long string:

```text
year,data
1901,-7.67241907119751
1902,-7.862711429595947
1903,-7.910782814025879
...
```

We have to break this into lines before giving it to `csv.reader`,
and we can do that by splitting the string on the same `\n` escape sequence
we encountered a few moments ago.
To see how this works,
let's read `test-01.csv` into memory and split it into pieces:

```python
with open('test-01.csv', 'r') as reader:
    data = reader.read()
    lines = data.split('\n')
    print(lines)
```
{: title="syndicate/read-csv-06.py"}
```text
['1901,12.3', '1902,45.6', '1903,78.9', '']
```

That's *almost* right, but why is there an empty string at the end of the list?
The answer is that the last line of the file ends in a newline,
so Python does the same thing it does in the example below:

```python
fields = 'a-b-'.split('-')
print(fields)
```
```text
['a', 'b', '']
```

The solution once again is to strip leading and trailing whitespace before splitting:

```python
with open('test-01.csv', 'r') as reader:
    data = reader.read()
    lines = data.strip().split('\n')
    print(lines)
```
{: title="syndicate/read-csv-07.py"}
```text
['1901,12.3', '1902,45.6', '1903,78.9']
```

Putting this all together, we can get data for Canada like this:

```python
import requests
import csv

url = 'http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/CAN.csv'
response = requests.get(url)
if response.status_code != 200:
    print('Failed to get data:', response.status_code)
else:
    wrapper = csv.reader(response.text.strip().split('\n'))
    for record in wrapper:
        print(record)
```
{: title="syndicate/get-tas-can-csv.py"}
```text
['year', 'data']
['1901', '-7.67241907119751']
['1902', '-7.862711429595947']
['1903', '-7.910782814025879']
['1904', '-8.155729293823242']
['1905', '-7.547311305999756']
...
```

That looks like progress,
so let's convert the data from strings to the numbers we actually want:

```python
import requests
import csv

url = 'http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/CAN.csv'
response = requests.get(url)
if response.status_code != 200:
    print('Failed to get data:', response.status_code)
else:
    wrapper = csv.reader(response.text.strip().split('\n'))
    for record in wrapper:
        year = int(record[0])
        value = float(record[1])
        print(year, value)
```
{: title="syndicate/get-tas-can-convert.py"}
```text
Traceback (most recent call last):
  File "api-with-naive-converting.py", line 11, in <module>
    year = int(record[0])
ValueError: invalid literal for int() with base 10: 'year'
```

The error occurs because the first line of data is:

```text
year,data
```

When we try to convert the string `'year'` to an integer,
Python quite rightly complains.
The fix is straightforward:
we just need to ignore lines that start with the word `year`:

```python
import requests
import csv

url = 'http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/CAN.csv'
response = requests.get(url)
if response.status_code != 200:
    print('Failed to get data:', response.status_code)
else:
    wrapper = csv.reader(response.text.strip().split('\n'))
    results = []
    for record in wrapper:
        if record[0] != 'year':
            year = int(record[0])
            value = float(record[1])
            print(year, value)
```
{: src="syndicate/get-tas-can-clean.py"}
```text
1901 -7.67241907119751
1902 -7.862711429595947
1903 -7.910782814025879
1904 -8.155729293823242
1905 -7.547311305999756
...
```

========================================

---
title: "Generalizing and Handling Errors"
teaching: 15
exercises: 0
questions:
- "FIXME"
objectives:
- "Turn a script into a function."
- "Make a function more robust by explicitly handling errors."
keypoints:
- "FIXME"
---

Now that we know how to get the data for Canada,
let's create a function that will do the same thing for an arbitrary country.
The steps are simple:

1.  copy the code we've written into a function that takes a 3-letter country code as a parameter,
2.  insert that country code into the URL at the appropriate place, and
3.  return the result as a list instead of printing it.

The resulting function looks like:

```
def annual_mean_temp(country):
    '''Get the annual mean temperature for a country given its 3-letter ISO code (such as "CAN").'''
    url = 'http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/' + country + '.csv'
    response = requests.get(url)
    if response.status_code != 200:
        print('Failed to get data:', response.status_code)
    else:
        wrapper = csv.reader(response.text.strip().split('\n'))
        results = []
        for record in wrapper:
            if record[0] != 'year':
                year = int(record[0])
                value = float(record[1])
                results.append([year, value])
        return results
```
{: .python}

This works:

```
canada = annual_mean_temp('CAN')
print('first three entries for Canada:', canada[:3])
```
{: .python}
```
first three entries for Canada: [[1901, -7.67241907119751], [1902, -7.862711429595947], [1903, -7.910782814025879]]
```
{: .output}

However,
there's a problem.
Look what happens when we pass in an invalid country identifier:

```
latveria = annual_mean_temp('LTV')
print 'first three entries for Latveria:', latveria[:3]
```
{: .python}
```
first three entries for Latveria: []
```
{: .output}

Latveria doesn't exist,
so why is our function returning an empty list rather than printing an error message?
The non-appearance of an error message must mean that the response code was 200;
if it was anything else,
we would have gone into the `if` branch,
printed a message,
and returned `None`
(which is what functions do when they're not told to return anything specific).

So if the response code was 200 and there was no data, that would explain what we're seeing.
Let's check:

```
def annual_mean_temp(country):
    '''Get the annual mean temperature for a country given its 3-letter ISO code (such as "CAN").'''
    url = 'http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/' + country + '.csv'
    print('url used is', url)
    response = requests.get(url)
    print('response code:', response.status_code)
    print('length of data:', len(response.text))
    if response.status_code != 200:
        print('Failed to get data:', response.status_code)
    else:
        wrapper = csv.reader(response.text.strip().split('\n'))
        results = []
        for record in wrapper:
            if record[0] != 'year':
                year = int(record[0])
                value = float(record[1])
                results.append([year, value])
        return results

latveria = annual_mean_temp('LTV')
print('number of records for Latveria:', len(latveria))
```
{: .python}
```
url used is http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/LTV.csv
response code: 200
length of data: 0
number of records for Latveria: 0
```
{: .output}

In other words,
the World Bank is always saying,
"I was able to answer your query,"
even when it actually can't.
After a bit more experimenting, we discover that the site *always* returns a 200 status code.
The only way to tell if there's real data or not is to check if `response.text` is empty.
Here's the updated function:

```
def annual_mean_temp(country):
    '''
    Get the annual mean temperature for a country given its 3-letter ISO code (such as "CAN").
    Returns an empty list if the country code is invalid.
    '''
    url = 'http://climatedataapi.worldbank.org/climateweb/rest/v1/country/cru/tas/year/' + country + '.csv'
    response = requests.get(url)
    results = []
    if len(response.text) > 0:
        wrapper = csv.reader(response.text.strip().split('\n'))
        for record in wrapper:
            if record[0] != 'year':
                year = int(record[0])
                value = float(record[1])
                results.append([year, value])
    return results

print('number of records for Canada:', len(annual_mean_temp('CAN')))
print('number of records for Latveria:', len(annual_mean_temp('LTV')))
```
{: .python}
```
number of records for Canada: 109
number of records for Latveria: 0
```
{: .output}

Now that we can get surface temperatures for different countries,
we can write a function to compare those values.
(We'll jump straight into writing a function because by now it's clear that's what we're eventually going to do anyway.)
Here's our first attempt:

```
def diff_records(left, right):
    '''Given lists of [year, value] pairs, return list of [year, difference] pairs.'''
    num_years = len(left)
    results = []
    for i in range(num_years):
        left_year, left_value = left[i]
        right_year, right_value = right[i]
        difference = left_value - right_value
        results.append([left_year, difference])
    return results
```
{: .python}

Here, we're using the number of entries in `left` (which we find with `len(left)`) to control our loop.
The expression:

```
for i in range(num_years):
```
{: .python}

runs `i` from 0 to `num_years-1`, which corresponds exactly to the legal indices of `left`.
Inside the loop we unpack the left and right years and values from the list entries,
then append a pair containing a year and a difference to `results`,
which we return at the end.

To see if this function works, we can run a couple of tests on made-up data:

```
print('one record:', diff_records([[1900, 1.0]],
                                  [[1900, 2.0]]))
print('two records:', diff_records([[1900, 1.0], [1901, 10.0]],
                                   [[1900, 2.0], [1901, 20.0]]))
```
{: .python}
```
one record: [[1900, -1.0]]
two records: [[1900, -1.0], [1901, -10.0]]
```
{: .output}

That looks pretty good—but what about these cases?

```
print('mis-matched years:', diff_records([[1900, 1.0]],
                                         [[1999, 2.0]]))
print('left is shorter', diff_records([[1900, 1.0]],
                                      [[1900, 10.0], [1901, 20.0]]))
print('right is shorter', diff_records([[1900, 1.0], [1901, 2.0]],
                                       [[1900, 10.0]]))
```
{: .python}
```
---------------------------------------------------------------------------
IndexError                                Traceback (most recent call last)
<ipython-input-15-7582f56db8bf> in <module>()
      4                                       [[1900, 10.0], [1901, 20.0]])
      5 print('right is shorter', diff_records([[1900, 1.0], [1901, 2.0]],
----> 6                                        [[1900, 10.0]]))

<ipython-input-13-67464343fd99> in diff_records(left, right)
      5     for i in range(num_years):
      6         left_year, left_value = left[i]
----> 7         right_year, right_value = right[i]
      8         difference = left_value - right_value
      9         results.append([left_year, difference])

IndexError: list index out of rangemis-matched years: [[1900, -1.0]]
left is shorter [[1900, -9.0]]
right is shorter
```
{: .error}

The first test gives us an answer even though the years didn't match:
we get a result, but it's meaningless.
The second case gives us a partial result,
again without telling us there's a problem,
while the third crashes because we're using `left` to determine the number of records,
but `right` doesn't have that many.

The first two problems are actually worse than the third
because they are [silent failures](../gloss/#g:silent-failure):
the function does the wrong thing, but doesn't indicate that in any way.
Let's fix that:

```
def diff_records(left, right):
    '''
    Given lists of [year, value] pairs, return list of [year, difference] pairs.
    Fails if the inputs are not for exactly corresponding years.
    '''
    assert len(left) == len(right), \
           'Inputs have different lengths.'
    num_years = len(left)
    results = []
    for i in range(num_years):
        left_year, left_value = left[i]
        right_year, right_value = right[i]
        assert left_year == right_year, \
               'Record {0} is for different years: {1} vs {2}'.format(i, left_year, right_year)
        difference = left_value - right_value
        results.append([left_year, difference])
    return results
```
{: .python}

Do our "good" tests pass?

```
print('one record:', diff_records([[1900, 1.0]],
                                  [[1900, 2.0]]))
print('two records:', diff_records([[1900, 1.0], [1901, 10.0]],
                                   [[1900, 2.0], [1901, 20.0]]))
```
{: .python}
```
one record: [[1900, -1.0]]
two records: [[1900, -1.0], [1901, -10.0]]
```
{: .output}

What about our the three tests that we now expect to fail?

```
print('mis-matched years:', diff_records([[1900, 1.0]],
                                         [[1999, 2.0]]))
```
{: .python}
```
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-18-c101917a748e> in <module>()
      1 print('mis-matched years:', diff_records([[1900, 1.0]],
----> 2                                          [[1999, 2.0]]))

<ipython-input-16-d41327791c15> in diff_records(left, right)
     10         left_year, left_value = left[i]
     11         right_year, right_value = right[i]
---> 12         assert left_year == right_year,                'Record {0} is for different years: {1} vs {2}'.format(i, left_year, right_year)
     13         difference = left_value - right_value
     14         results.append([left_year, difference])

AssertionError: Record 0 is for different years: 1900 vs 1999mis-matched years:
```
{: .error}

```
print('left is shorter', diff_records([[1900, 1.0]],
                                      [[1900, 10.0], [1901, 20.0]]))
```
{: .python}
```
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-19-682d448d921e> in <module>()
      1 print('left is shorter', diff_records([[1900, 1.0]],
----> 2                                       [[1900, 10.0], [1901, 20.0]]))

<ipython-input-16-d41327791c15> in diff_records(left, right)
      4     Fails if the inputs are not for exactly corresponding years.
      5     '''
----> 6     assert len(left) == len(right),            'Inputs have different lengths.'
      7     num_years = len(left)
      8     results = []

AssertionError: Inputs have different lengths. left is shorter
```
{: .error}
```
print('right is shorter', diff_records([[1900, 1.0], [1901, 2.0]],
                                       [[1900, 10.0]]))
```
{: .python}
```
---------------------------------------------------------------------------
AssertionError                            Traceback (most recent call last)
<ipython-input-20-a475e608dd70> in <module>()
      1 print('right is shorter', diff_records([[1900, 1.0], [1901, 2.0]],
----> 2                                        [[1900, 10.0]]))

<ipython-input-16-d41327791c15> in diff_records(left, right)
      4     Fails if the inputs are not for exactly corresponding years.
      5     '''
----> 6     assert len(left) == len(right),            'Inputs have different lengths.'
      7     num_years = len(left)
      8     results = []

AssertionError: Inputs have different lengths. right is shorter
```
{: .error}

Excellent: the assertions we've added will now alert us if we try to work with badly-formatted or inconsistent data.

> ## Error Handling
>
> Python scripts should have error handling code because:
>
> 1.  Python is an inherently unreliable language.
> 2.  Functions can return errors.
> 3.  One should never trust the data provided is what is expected.
> 4.  A python script would stop on an error, so the task wouldn't be accomplished.
{: .challenge}

> ## When to Complain?
>
> We have actually just committed the same mistake as the World Bank:
> if someone gives `annual_mean_temp` an invalid country identifier,
> it doesn't report an error,
> but instead returns an empty list,
> so the caller has to somehow know to look for that.
> Should it use an assertion to fail if it doesn't get data?
> Why or why not?
{: .challenge}

> ## Enumerating
>
> Python includes a function called `enumerate` that's often used in `for` loops.
> This loop:
>
> ```
> for (i, c) in enumerate('abc'):
>     print(i, '=', c)
> ```
> {: .python}
>
> prints:
>
> ```
> 0 = a
> 1 = b
> 2 = c
> ```
> {: .output}
>
> Rewrite `diff_records` to use `enumerate`.
{: .challenge}
---
title: "Visualization"
teaching: 15
exercises: 0
questions:
- "FIXME"
objectives:
- "Construct a simple visualization using pyplot."
keypoints:
- "FIXME"
---

Long lists of numbers are not particularly useful,
but we now have the tools we need to visualize the temperature differences between countries:

```
from matplotlib import pyplot as plt

australia = annual_mean_temp('AUS')
canada = annual_mean_temp('CAN')
diff = diff_records(australia, canada)
plt.plot(diff)
plt.show()
```
{: .python}

![First Plot]({{ site.github.url }}/fig/plot-01.png)

That's not what we want:
pyplot has interpreted the list of pairs returned by `annual_mean_temp`
as two corresponding curves rather than as the (x,y) coordinates for one curve.
Let's convert our list of (year, difference) pairs into a NumPy array:

```
import numpy as np
d = np.array(diff)
```
{: .python}

and then plot the first column against the second:

```
plt.plot(d[:, 0], d[:, 1])
plt.show()
```
{: .python}

![Second Plot]({{ site.github.url }}/fig/plot-02.png)

It looks like the difference is slowly decreasing, but the signal is very noisy.
At this point, if we wanted to do some real science,
it would be time to use a curve-fitting library
or calculate some meaningful statistics.

> ## Changing Visualizations
>
> Modify the plotting commands so that the Y-axis scale runs from 0 to 32.
> Do you think this gives you a more accurate or less accurate view of this data?
{: .challenge}
---
title: "Publishing Data"
teaching: 15
exercises: 0
questions:
- "FIXME"
objectives:
- "Write Python programs that share static data sets."
keypoints:
- "FIXME"
---

We now have functions to download temperature data for different countries and find annual differences.
The next step is to share our findings with the world by publishing the data sets we generate.
To do this, we have to answer three questions:

-   How are we going to store the data?
-   How are people going to download it?
-   How are people going to find it?

The first question is the easiest to answer:
`diff_records` returns a list of (year, difference) pairs that we can write out as a CSV file:

```
import csv

def save_records(filename, records):
    '''Save a list of [year, temp] pairs as CSV.'''
    with open(filename, 'w') as raw:
        writer = csv.writer(raw)
        writer.writerows(records)
```
{: .python}

> ## Lessons Learned
>
> We use the `csv` library to write data
> for the same reason we use it to read:
> it correctly handles special cases (such as text containing commas).
{: .callout}

Let's test it:

```
save_records('temp.csv', [[1, 2], [3, 4]])
```
{: .python}

If we then look in the file `temp.csv`, we find:

```
1,2
3,4
```
{: .source}

as desired.

Now, where should this file go?
The answer is clearly "a server",
since data on our laptop is only accessible when we're online
(and probably not even then, since most people don't run a web server on their laptop).
But where on the server, and what should we call it?

The answer to those questions depends on how the server is set up.
On many multi-user Linux machines,
users can create a directory called like `public_html` under their home directory,
and the web server will automatically search in those directories.
For example,
if Nelle has a file called `thesis.pdf` in her `public_html` directory,
the web server will find it when it gets the URL `http://the.server.name/~nelle/thesis.pdf`.
(The tilde `~` in front of Nelle's name is what tells the web server
to look in Nelle's `public_html` directory.)
The specifics differ from one machine to the next,
but the basic idea stays the same.

As for what we should call it, here we return to the key idea in REST:
every data set should be identified by a "guessable" URL.
In our case we'll use a name  like `left-right.csv`,
where `left` and `right` are the three-letter codes of the countries whose temperatures we are differencing.
We can then tell people that if they want to compare Australia and Brazil,
they should look for `http://the.server.name/~nelle/AUS-BRA.csv`.
(We use upper case to be consistent with the World Bank's API.)

But what's to prevent someone from creating a badly-named (and therefore unfindable) file?
Someone could, for example, call `save_records('aus+bra.csv', records)`.
To reduce the odds of this happening,
let's modify `save_records` to take country identifiers as parameters:

```
import csv

def save_records(left, right, records):
    '''Save a list of [year, temp] pairs as CSV.'''
    filename = left + '-' + right + '.csv'
    with open(filename, 'w') as raw:
        writer = csv.writer(raw)
        writer.writerows(records)
```
{: .python}

We can now call it like this:

```
save_records('AUS', 'BRA', [[1, 2], [3, 4]])
```
{: .python}

and then check that the right output file has been created.
We are bound to have the country codes anyway (having used them to look up our data),
so this should seem natural to our users.

> ## Deciding What to Check
>
> Should `save_records` check that every record in its input has exactly two fields?
> Why or why not?
> What about country codes -
> should it contain a list of those that match actual countries
> and check that `left` and `right` are in that list?
{: .challenge}

> ## Setting Up Locally
>
> Find out how to publish a file on your department's server.
{: .challenge}

> ## Published Data Consistency
>
> It is important for the file names of published data to be consistent because:
>
> 1.  Some operating systems (e.g. Windows) treat spaces differently.
> 2.  You may not have access to your department's server to rename them.
> 3.  The `csv` library requires it.
> 4.  Programs can only process files and data correctly when they are.
{: .challenge}
---
title: "Making Data Findable"
teaching: 15
exercises: 0
questions:
- "FIXME"
objectives:
- "FIXME"
keypoints:
- "Make data sets more useful by providing metadata."
---

It's not enough to tell people what the rule is for creating filenames,
since that doesn't tell them what data sets we've actually generated.
The final step in this lesson is therefoore
to make the data we generate findable
by creating an [index](../gloss/#g:index) to tell people what files exist.

Here's the format we will use:

```
2014-05-26,FRA,TCD,FRA-TCD.csv
2014-05-27,AUS,BRA,AUS-BRA.csv
2014-05-27,AUS,CAN,AUS-CAN.csv
2014-05-28,BRA,CAN,BRA-CAN.csv
```
{: .source}

The columns are the date the data set was generated,
the identifiers of the two countries being compared,
and the name of the data file.
We include the date to make it easy for people to see what's been updated when,
but why do we bother to include the filename?
After all, we can re-generate it easily given the two country codes.
The answer is that while *we* know the rule for generating filenames,
other people's programs shouldn't have to.

Here's a function that updates the index file every time we generate a new data file:

```
import time

def update_index(index_filename, left, right):
    '''Append a record to the index.'''

    # Read existing data.
    with open(index_filename, 'r') as raw:
        reader = csv.reader(raw)
        records = []
        for r in reader:
            records.append(r)
    
    # Create new record.
    timestamp = time.strftime('%Y-%m-%d')
    data_filename = left + '-' + right + '.csv'
    new_record = (timestamp, left, right, data_filename)
    
    # Save.
    records.append(new_record)
    with open(index_filename, 'w') as raw:
        writer = csv.writer(raw)
        writer.writerows(records)
```
{: .python}

Let's test it.
If our index file contains:

```
2014-05-26,FRA,TCD,FRA-TCD.csv
2014-05-27,AUS,BRA,AUS-BRA.csv
2014-05-27,AUS,CAN,AUS-CAN.csv
2014-05-28,BRA,CAN,BRA-CAN.csv
```
{: .source}

and we run:

```
update_index('data/index.csv', 'TCD', 'CAN')
```
{: .python}

then our index file now contains:

```
2014-05-26,FRA,TCD,FRA-TCD.csv
2014-05-27,AUS,BRA,AUS-BRA.csv
2014-05-27,AUS,CAN,AUS-CAN.csv
2014-05-28,BRA,CAN,BRA-CAN.csv
2014-05-29,TCD,CAN,TCD-CAN.csv
```
{: .source}

Now that all of this is in place,
it's easy for us—and other people—to do new and exciting things with our data.
For example,
we can easily write a small program that tells us what data sets include information about a particular country
*and* have been published since we last checked:

```
def what_is_available(index_file, country, after):
    '''What data files include a country and have been published since 'after'?'''
    with open(index_file, 'r') as raw:
        reader = csv.reader(raw)
        filenames = []
        for record in reader:
            if (after <= record[0]) and (country in (record[1], record[2])):
                filenames.append(record[3])
    return filenames

print what_is_available('data/index.csv', 'BRA', '2014-05-27')
```
{: .python}
```
['AUS-BRA.csv', 'BRA-CAN.csv']
```
{: .output}

> ## New Kinds of Science
>
> This may not seem like a breakthrough,
> but it is actually an example of how the web helps researchers do new kinds of science.
> With a little bit more work,
> we could create a file on *our* machine to record when we last ran `what_is_available` for each of several different sites that are producing data.
> Each time we run it, our program would:
>
> *   read our local "what to check" file;
> *   ask each data source whether it had any new data for us;
> *   download and process that data; and
> *   present us with a summary of the results.
>
> This is exactly how blogs work.
> Every blog reader keeps a list of blog URLs that it's supposed to check.
> When it is run, it goes to each of those sites and asks them for their index file (which is typically called something like `feed.xml`).
> It then checks the articles listed in that index against its local record of what has already been seen,
> then downloads any articles that are new.
> By automating this process, blogging tools help us focus attention on things that are actually worth looking at.
{: .callout}

> ## Indexing
>
> We should always create an index for generated data because:
>
> 1.  It can be checked in an automated way for changes.
> 2.  The web server will not display the directory without an index.
> 3.  REST APIs require an index to function.
> 4.  It is too complicated for a program to calculate itself.
{: .challenge}

> ## Metadata for Metadata
>
> Should the first line of the index file be a header giving the names of the columns?
> Why or why not?
{: .challenge}

> ## To Automate or Not
>
> Should `update_index` be called inside `save_records`
> so that the index is automatically updated every time a new data set is generated?
> Why or why not?
{: .challenge}

> ## Removing Redundant Redundancy
>
> `update_index` and `save_records` both construct the name of the data file.
> Refactor them to remove this redundancy.
{: .challenge}
